#' Adaptive_avg_pool1d
#'
#' @section adaptive_avg_pool1d(input, output_size) -> Tensor :
#'
#' Applies a 1D adaptive average pooling over an input signal composed of
#' several input planes.
#' 
#' See `~torch.nn.AdaptiveAvgPool1d` for details and output shape.
#'
#'
#' @param output_size NA the target output size (single integer)
#'
#' @name nnf_adaptive_avg_pool1d
#'
#' @export
NULL


#' Adaptive_avg_pool2d
#'
#' Applies a 2D adaptive average pooling over an input signal composed of
#'     several input planes.
#' 
#'     See `~torch.nn.AdaptiveAvgPool2d` for details and output shape.
#'
#' @param output_size NA the target output size (single integer or        double-integer tuple)
#'
#' @name nnf_adaptive_avg_pool2d
#'
#' @export
NULL


#' Adaptive_avg_pool3d
#'
#' Applies a 3D adaptive average pooling over an input signal composed of
#'     several input planes.
#' 
#'     See `~torch.nn.AdaptiveAvgPool3d` for details and output shape.
#'
#' @param output_size NA the target output size (single integer or        triple-integer tuple)
#'
#' @name nnf_adaptive_avg_pool3d
#'
#' @export
NULL


#' Adaptive_max_pool1d
#'
#' Applies a 1D adaptive max pooling over an input signal composed of
#'     several input planes.
#' 
#'     See `~torch.nn.AdaptiveMaxPool1d` for details and output shape.
#'
#' @param output_size NA the target output size (single integer)
#' @param return_indices NA whether to return pooling indices. Default: ``False``
#'
#' @name nnf_adaptive_max_pool1d
#'
#' @export
NULL


#' Adaptive_max_pool1d_with_indices
#'
#' Applies a 1D adaptive max pooling over an input signal composed of
#'     several input planes.
#' 
#'     See `~torch.nn.AdaptiveMaxPool1d` for details and output shape.
#'
#' @param output_size NA the target output size (single integer)
#' @param return_indices NA whether to return pooling indices. Default: ``False``
#'
#' @name nnf_adaptive_max_pool1d_with_indices
#'
#' @export
NULL


#' Adaptive_max_pool2d
#'
#' Applies a 2D adaptive max pooling over an input signal composed of
#'     several input planes.
#' 
#'     See `~torch.nn.AdaptiveMaxPool2d` for details and output shape.
#'
#' @param output_size NA the target output size (single integer or        double-integer tuple)
#' @param return_indices NA whether to return pooling indices. Default: ``False``
#'
#' @name nnf_adaptive_max_pool2d
#'
#' @export
NULL


#' Adaptive_max_pool2d_with_indices
#'
#' Applies a 2D adaptive max pooling over an input signal composed of
#'     several input planes.
#' 
#'     See `~torch.nn.AdaptiveMaxPool2d` for details and output shape.
#'
#' @param output_size NA the target output size (single integer or        double-integer tuple)
#' @param return_indices NA whether to return pooling indices. Default: ``False``
#'
#' @name nnf_adaptive_max_pool2d_with_indices
#'
#' @export
NULL


#' Adaptive_max_pool3d
#'
#' Applies a 3D adaptive max pooling over an input signal composed of
#'     several input planes.
#' 
#'     See `~torch.nn.AdaptiveMaxPool3d` for details and output shape.
#'
#' @param output_size NA the target output size (single integer or        triple-integer tuple)
#' @param return_indices NA whether to return pooling indices. Default: ``False``
#'
#' @name nnf_adaptive_max_pool3d
#'
#' @export
NULL


#' Adaptive_max_pool3d_with_indices
#'
#' Applies a 3D adaptive max pooling over an input signal composed of
#'     several input planes.
#' 
#'     See `~torch.nn.AdaptiveMaxPool3d` for details and output shape.
#'
#' @param output_size NA the target output size (single integer or        triple-integer tuple)
#' @param return_indices NA whether to return pooling indices. Default: ``False``
#'
#' @name nnf_adaptive_max_pool3d_with_indices
#'
#' @export
NULL


#' Affine_grid
#'
#' @section Generates a 2D or 3D flow field (sampling grid), given a batch of :
#'
#' Generates a 2D or 3D flow field (sampling grid), given a batch of
#'     affine matrices `theta`.
#' 
#'     .. note::
#'         This function is often used in conjunction with [`grid_sample`]
#'         to build `Spatial Transformer Networks`_ .
#'
#'
#' @param theta (Tensor) input batch of affine matrices with shape        (\eqn{N \times 2 \times 3}) for 2D or        (\eqn{N \times 3 \times 4}) for 3D
#' @param size (torch.Size) the target output image size.        (\eqn{N \times C \times H \times W} for 2D or        \eqn{N \times C \times D \times H \times W} for 3D)        Example: torch.Size((32, 3, 24, 24))
#' @param align_corners (bool, optional) if ``True``, consider ``-1`` and ``1``        to refer to the centers of the corner pixels rather than the image corners.        Refer to [`grid_sample`] for a more complete description.        A grid generated by [`affine_grid`] should be passed to [`grid_sample`]        with the same setting for this option.        Default: ``False``
#'
#' @name nnf_affine_grid
#'
#' @export
NULL





#' Avg_pool1d
#'
#' @section avg_pool1d(input, kernel_size, stride=None, padding=0, ceil_mode=False, count_include_pad=True) -> Tensor :
#'
#' Applies a 1D average pooling over an input signal composed of several
#' input planes.
#' 
#' See `~torch.nn.AvgPool1d` for details and output shape.
#'
#'
#' @param input NA input tensor of shape \eqn{(\text{minibatch} , \text{in\_channels} , iW)}
#' @param kernel_size NA the size of the window. Can be a single number or a      tuple `(kW,)`
#' @param stride NA the stride of the window. Can be a single number or a tuple      `(sW,)`. Default: `kernel_size`
#' @param padding NA implicit zero paddings on both sides of the input. Can be a      single number or a tuple `(padW,)`. Default: 0
#' @param ceil_mode NA when True, will use `ceil` instead of `floor` to compute the        output shape. Default: ``False``
#' @param count_include_pad NA when True, will include the zero-padding in the        averaging calculation. Default: ``True``
#'
#' @name nnf_avg_pool1d
#'
#' @export
NULL


#' Avg_pool2d
#'
#' @section avg_pool2d(input, kernel_size, stride=None, padding=0, ceil_mode=False, count_include_pad=True, divisor_override=None) -> Tensor :
#'
#' Applies 2D average-pooling operation in \eqn{kH \times kW} regions by step size
#' \eqn{sH \times sW} steps. The number of output features is equal to the number of
#' input planes.
#' 
#' See `~torch.nn.AvgPool2d` for details and output shape.
#'
#'
#' @param input NA input tensor \eqn{(\text{minibatch} , \text{in\_channels} , iH , iW)}
#' @param kernel_size NA size of the pooling region. Can be a single number or a      tuple `(kH, kW)`
#' @param stride NA stride of the pooling operation. Can be a single number or a      tuple `(sH, sW)`. Default: `kernel_size`
#' @param padding NA implicit zero paddings on both sides of the input. Can be a      single number or a tuple `(padH, padW)`. Default: 0
#' @param ceil_mode NA when True, will use `ceil` instead of `floor` in the formula        to compute the output shape. Default: ``False``
#' @param count_include_pad NA when True, will include the zero-padding in the        averaging calculation. Default: ``True``
#' @param divisor_override NA if specified, it will be used as divisor, otherwise         size of the pooling region will be used. Default: None
#'
#' @name nnf_avg_pool2d
#'
#' @export
NULL


#' Avg_pool3d
#'
#' @section avg_pool3d(input, kernel_size, stride=None, padding=0, ceil_mode=False, count_include_pad=True, divisor_override=None) -> Tensor :
#'
#' Applies 3D average-pooling operation in \eqn{kT \times kH \times kW} regions by step
#' size \eqn{sT \times sH \times sW} steps. The number of output features is equal to
#' \eqn{\lfloor\frac{\text{input planes}}{sT}\rfloor}.
#' 
#' See `~torch.nn.AvgPool3d` for details and output shape.
#'
#'
#' @param input NA input tensor \eqn{(\text{minibatch} , \text{in\_channels} , iT \times iH , iW)}
#' @param kernel_size NA size of the pooling region. Can be a single number or a      tuple `(kT, kH, kW)`
#' @param stride NA stride of the pooling operation. Can be a single number or a      tuple `(sT, sH, sW)`. Default: `kernel_size`
#' @param padding NA implicit zero paddings on both sides of the input. Can be a      single number or a tuple `(padT, padH, padW)`, Default: 0
#' @param ceil_mode NA when True, will use `ceil` instead of `floor` in the formula        to compute the output shape
#' @param count_include_pad NA when True, will include the zero-padding in the        averaging calculation
#' @param divisor_override NA if specified, it will be used as divisor, otherwise        size of the pooling region will be used. Default: None
#'
#' @name nnf_avg_pool3d
#'
#' @export
NULL





#' Bilinear
#'
#' Applies a bilinear transformation to the incoming data:
#'     \eqn{y = x_1 A x_2 + b}
#' 
#'     Shape:
#' 
#'         - input1: \eqn{(N, *, H_{in1})} where \eqn{H_{in1}=\text{in1\_features}}
#'           and \eqn{*} means any number of additional dimensions.
#'           All but the last dimension of the inputs should be the same.
#'         - input2: \eqn{(N, *, H_{in2})} where \eqn{H_{in2}=\text{in2\_features}}
#'         - weight: \eqn{(\text{out\_features}, \text{in1\_features},
#'           \text{in2\_features})}
#'         - bias: \eqn{(\text{out\_features})}
#'         - output: \eqn{(N, *, H_{out})} where \eqn{H_{out}=\text{out\_features}}
#'           and all but the last dimension are the same shape as the input.
#'
#'
#'
#' @name nnf_bilinear
#'
#' @export
NULL








#' Boolean_dispatch
#'
#' Dispatches to either of 2 script functions based on a boolean argument.
#'     In TorchScript, the boolean argument must be constant so that the correct
#'     function to use can be determined at compile time.
#'
#'
#'
#' @name nnf_boolean_dispatch
#'
#' @export
NULL


#' Conv_tbc
#'
#' Applies a 1-dimensional sequence convolution over an input sequence.
#' Input and output dimensions are (Time, Batch, Channels) - hence TBC.
#'
#' @param input NA input tensor of shape \eqn{(\text{sequence length} \times batch \times \text{in\_channels})}
#' @param weight NA filter of shape (\eqn{\text{kernel width} \times \text{in\_channels} \times \text{out\_channels}})
#' @param bias NA bias of shape (\eqn{\text{out\_channels}})
#' @param pad NA number of timesteps to pad. Default: 0
#'
#' @name nnf_conv_tbc
#'
#' @export
NULL
























#' Fractional_max_pool2d
#'
#' Applies 2D fractional max pooling over an input signal composed of several input planes.
#' 
#'     Fractional MaxPooling is described in detail in the paper `Fractional MaxPooling`_ by Ben Graham
#' 
#'     The max-pooling operation is applied in \eqn{kH \times kW} regions by a stochastic
#'     step size determined by the target output size.
#'     The number of output features is equal to the number of input planes.
#'
#' @param kernel_size NA the size of the window to take a max over.                 Can be a single number \eqn{k} (for a square kernel of \eqn{k \times k})                 or a tuple `(kH, kW)`
#' @param output_size NA the target output size of the image of the form \eqn{oH \times oW}.                 Can be a tuple `(oH, oW)` or a single number \eqn{oH} for a square image \eqn{oH \times oH}
#' @param output_ratio NA If one wants to have an output size as a ratio of the input size, this option can be given.                  This has to be a number or tuple in the range (0, 1)
#' @param return_indices NA if ``True``, will return the indices along with the outputs.                    Useful to pass to [`~torch.nn.functional.max_unpool2d`].
#'
#' @name nnf_fractional_max_pool2d
#'
#' @export
NULL


#' Fractional_max_pool2d_with_indices
#'
#' Applies 2D fractional max pooling over an input signal composed of several input planes.
#' 
#'     Fractional MaxPooling is described in detail in the paper `Fractional MaxPooling`_ by Ben Graham
#' 
#'     The max-pooling operation is applied in \eqn{kH \times kW} regions by a stochastic
#'     step size determined by the target output size.
#'     The number of output features is equal to the number of input planes.
#'
#' @param kernel_size NA the size of the window to take a max over.                 Can be a single number \eqn{k} (for a square kernel of \eqn{k \times k})                 or a tuple `(kH, kW)`
#' @param output_size NA the target output size of the image of the form \eqn{oH \times oW}.                 Can be a tuple `(oH, oW)` or a single number \eqn{oH} for a square image \eqn{oH \times oH}
#' @param output_ratio NA If one wants to have an output size as a ratio of the input size, this option can be given.                  This has to be a number or tuple in the range (0, 1)
#' @param return_indices NA if ``True``, will return the indices along with the outputs.                    Useful to pass to [`~torch.nn.functional.max_unpool2d`].
#'
#' @name nnf_fractional_max_pool2d_with_indices
#'
#' @export
NULL


#' Fractional_max_pool3d
#'
#' Applies 3D fractional max pooling over an input signal composed of several input planes.
#' 
#'     Fractional MaxPooling is described in detail in the paper `Fractional MaxPooling`_ by Ben Graham
#' 
#'     The max-pooling operation is applied in \eqn{kT \times kH \times kW} regions by a stochastic
#'     step size determined by the target output size.
#'     The number of output features is equal to the number of input planes.
#'
#' @param kernel_size NA the size of the window to take a max over.                 Can be a single number \eqn{k} (for a square kernel of \eqn{k \times k \times k})                 or a tuple `(kT, kH, kW)`
#' @param output_size NA the target output size of the form \eqn{oT \times oH \times oW}.                 Can be a tuple `(oT, oH, oW)` or a single number \eqn{oH} for a cubic output                  \eqn{oH \times oH \times oH}
#' @param output_ratio NA If one wants to have an output size as a ratio of the input size, this option can be given.                  This has to be a number or tuple in the range (0, 1)
#' @param return_indices NA if ``True``, will return the indices along with the outputs.                    Useful to pass to [`~torch.nn.functional.max_unpool3d`].
#'
#' @name nnf_fractional_max_pool3d
#'
#' @export
NULL


#' Fractional_max_pool3d_with_indices
#'
#' Applies 3D fractional max pooling over an input signal composed of several input planes.
#' 
#'     Fractional MaxPooling is described in detail in the paper `Fractional MaxPooling`_ by Ben Graham
#' 
#'     The max-pooling operation is applied in \eqn{kT \times kH \times kW} regions by a stochastic
#'     step size determined by the target output size.
#'     The number of output features is equal to the number of input planes.
#'
#' @param kernel_size NA the size of the window to take a max over.                 Can be a single number \eqn{k} (for a square kernel of \eqn{k \times k \times k})                 or a tuple `(kT, kH, kW)`
#' @param output_size NA the target output size of the form \eqn{oT \times oH \times oW}.                 Can be a tuple `(oT, oH, oW)` or a single number \eqn{oH} for a cubic output                  \eqn{oH \times oH \times oH}
#' @param output_ratio NA If one wants to have an output size as a ratio of the input size, this option can be given.                  This has to be a number or tuple in the range (0, 1)
#' @param return_indices NA if ``True``, will return the indices along with the outputs.                    Useful to pass to [`~torch.nn.functional.max_unpool3d`].
#'
#' @name nnf_fractional_max_pool3d_with_indices
#'
#' @export
NULL



#' Grad
#'
#' Gradient interface
#'
#'
#'
#' @name nnf_grad
#'
#' @export
NULL


#' Grid_sample
#'
#' Given an `input` and a flow-field `grid`, computes the
#'     ``output`` using `input` values and pixel locations from `grid`.
#' 
#'     Currently, only spatial (4-D) and volumetric (5-D) `input` are
#'     supported.
#' 
#'     In the spatial (4-D) case, for `input` with shape
#'     \eqn{(N, C, H_\text{in}, W_\text{in})} and `grid` with shape
#'     \eqn{(N, H_\text{out}, W_\text{out}, 2)}, the output will have shape
#'     \eqn{(N, C, H_\text{out}, W_\text{out})}.
#' 
#'     For each output location ``output[n, :, h, w]``, the size-2 vector
#'     ``grid[n, h, w]`` specifies `input` pixel locations ``x`` and ``y``,
#'     which are used to interpolate the output value ``output[n, :, h, w]``.
#'     In the case of 5D inputs, ``grid[n, d, h, w]`` specifies the
#'     ``x``, ``y``, ``z`` pixel locations for interpolating
#'     ``output[n, :, d, h, w]``. `mode` argument specifies ``nearest`` or
#'     ``bilinear`` interpolation method to sample the input pixels.
#' 
#'     `grid` specifies the sampling pixel locations normalized by the
#'     `input` spatial dimensions. Therefore, it should have most values in
#'     the range of ``[-1, 1]``. For example, values ``x = -1, y = -1`` is the
#'     left-top pixel of `input`, and values  ``x = 1, y = 1`` is the
#'     right-bottom pixel of `input`.
#' 
#'     If `grid` has values outside the range of ``[-1, 1]``, the corresponding
#'     outputs are handled as defined by `padding_mode`. Options are
#' 
#'         * ``padding_mode="zeros"``: use ``0`` for out-of-bound grid locations,
#'         * ``padding_mode="border"``: use border values for out-of-bound grid locations,
#'         * ``padding_mode="reflection"``: use values at locations reflected by
#'           the border for out-of-bound grid locations. For location far away
#'           from the border, it will keep being reflected until becoming in bound,
#'           e.g., (normalized) pixel location ``x = -3.5`` reflects by border ``-1``
#'           and becomes ``x' = 1.5``, then reflects by border ``1`` and becomes
#'           ``x'' = -0.5``.
#' 
#'     .. note::
#'         This function is often used in conjunction with [`affine_grid`]
#'         to build `Spatial Transformer Networks`_ .
#'     .. include:: cuda_deterministic_backward.rst
#'
#' @param input (Tensor) input of shape \eqn{(N, C, H_\text{in}, W_\text{in})} (4-D case)                    or \eqn{(N, C, D_\text{in}, H_\text{in}, W_\text{in})} (5-D case)
#' @param grid (Tensor) flow-field of shape \eqn{(N, H_\text{out}, W_\text{out}, 2)} (4-D case)                   or \eqn{(N, D_\text{out}, H_\text{out}, W_\text{out}, 3)} (5-D case)
#' @param mode (str) interpolation mode to calculate output values        ``'bilinear'`` | ``'nearest'``. Default: ``'bilinear'``
#' @param padding_mode (str) padding mode for outside grid values        ``'zeros'`` | ``'border'`` | ``'reflection'``. Default: ``'zeros'``
#' @param align_corners (bool, optional) Geometrically, we consider the pixels of the        input  as squares rather than points.        If set to ``True``, the extrema (``-1`` and ``1``) are considered as referring        to the center points of the input's corner pixels. If set to ``False``, they        are instead considered as referring to the corner points of the input's corner        pixels, making the sampling more resolution agnostic.        This option parallels the ``align_corners`` option in        [`interpolate`], and so whichever option is used here        should also be used there to resize the input image before grid sampling.        Default: ``False``
#'
#' @name nnf_grid_sample
#'
#' @export
NULL





#' Handle_torch_function
#'
#' Implement a function with checks for __torch_function__ overrides.
#' 
#'     See torch::autograd::handle_torch_function for the equivalent of this
#'     function in the C++ implementation.
#' 
#'     Arguments
#'     ---------
#'     public_api : function
#'         Function exposed by the public torch API originally called like
#'         ``public_api(*args, **kwargs)`` on which arguments are now being
#'         checked.
#'     relevant_args : iterable
#'         Iterable of arguments to check for __torch_function__ methods.
#'     args : tuple
#'         Arbitrary positional arguments originally passed into ``public_api``.
#'     kwargs : tuple
#'         Arbitrary keyword arguments originally passed into ``public_api``.
#' 
#'     Returns
#'     -------
#'     Result from calling `implementation()` or an `__torch_function__`
#'     method, as appropriate.
#' 
#'     Raises
#'     ------
#'     TypeError : if no implementation is found.
#'
#'
#'
#' @name nnf_handle_torch_function
#'
#' @export
NULL





#' Hardsigmoid
#'
#' @section hardsigmoid(input) -> Tensor :
#'
#' Applies the element-wise function \eqn{\text{Hardsigmoid}(x) = \frac{ReLU6(x + 3)}{6}}
#'
#'
#' @param inplace NA If set to ``True``, will do this operation in-place. Default: ``False``
#'
#' @name nnf_hardsigmoid
#'
#' @export
NULL


#' Hardtanh
#'
#' @section hardtanh(input, min_val=-1., max_val=1., inplace=False) -> Tensor :
#'
#' Applies the HardTanh function element-wise. See `~torch.nn.Hardtanh` for more
#'     details.
#'
#'
#'
#'
#' @name nnf_hardtanh
#'
#' @export
NULL


#' Hardtanh_
#'
#' @section hardtanh_(input, min_val=-1., max_val=1.) -> Tensor :
#'
#' In-place version of [`~hardtanh`].
#'
#'
#'
#'
#' @name nnf_hardtanh_
#'
#' @export
NULL


#' Has_torch_function
#'
#' Check for __torch_function__ implementations in the elements of an iterable
#' 
#'     Arguments
#'     ---------
#'     relevant_args : iterable
#'         Iterable or aguments to check for __torch_function__ methods.
#' 
#'     Returns
#'     -------
#'     True if any of the elements of relevant_args have __torch_function__
#'     implementations, False otherwise.
#'
#'
#'
#' @name nnf_has_torch_function
#'
#' @export
NULL





#' Interpolate
#'
#' Down/up samples the input to either the given `size` or the given
#'     `scale_factor`
#' 
#'     The algorithm used for interpolation is determined by `mode`.
#' 
#'     Currently temporal, spatial and volumetric sampling are supported, i.e.
#'     expected inputs are 3-D, 4-D or 5-D in shape.
#' 
#'     The input dimensions are interpreted in the form:
#'     `mini-batch x channels x [optional depth] x [optional height] x width`.
#' 
#'     The modes available for resizing are: `nearest`, `linear` (3D-only),
#'     `bilinear`, `bicubic` (4D-only), `trilinear` (5D-only), `area`
#'
#' @param input (Tensor) the input tensor
#' @param size (int or Tuple[int] or Tuple[int, int] or Tuple[int, int, int]) output spatial size.
#' @param scale_factor (float or Tuple[float]) multiplier for spatial size. Has to match input size if it is a tuple.
#' @param mode (str) algorithm used for upsampling:        ``'nearest'`` | ``'linear'`` | ``'bilinear'`` | ``'bicubic'`` |        ``'trilinear'`` | ``'area'``. Default: ``'nearest'``
#' @param align_corners (bool, optional) Geometrically, we consider the pixels of the        input and output as squares rather than points.        If set to ``True``, the input and output tensors are aligned by the        center points of their corner pixels, preserving the values at the corner pixels.        If set to ``False``, the input and output tensors are aligned by the corner        points of their corner pixels, and the interpolation uses edge value padding        for out-of-boundary values, making this operation *independent* of input size        when `scale_factor` is kept the same. This only has an effect when `mode`        is ``'linear'``, ``'bilinear'``, ``'bicubic'`` or ``'trilinear'``.        Default: ``False``
#' @param recompute_scale_factor (bool, optional) recompute the scale_factor for use in the        interpolation calculation.  When `scale_factor` is passed as a parameter, it is used        to compute the `output_size`.  If `recompute_scale_factor` is ```True`` or not specified,        a new `scale_factor` will be computed based on the output and input sizes for use in the        interpolation computation (i.e. the computation will be identical to if the computed        `output_size` were passed-in explicitly).  Otherwise, the passed-in `scale_factor` will        be used in the interpolation computation.  Note that when `scale_factor` is floating-point,        the recomputed scale_factor may differ from the one passed in due to rounding and precision        issues.
#'
#' @name nnf_interpolate
#'
#' @export
NULL








#' Lp_pool1d
#'
#' Applies a 1D power-average pooling over an input signal composed of
#'     several input planes. If the sum of all inputs to the power of `p` is
#'     zero, the gradient is set to zero as well.
#' 
#'     See `~torch.nn.LPPool1d` for details.
#'
#'
#'
#' @name nnf_lp_pool1d
#'
#' @export
NULL


#' Lp_pool2d
#'
#' Applies a 2D power-average pooling over an input signal composed of
#'     several input planes. If the sum of all inputs to the power of `p` is
#'     zero, the gradient is set to zero as well.
#' 
#'     See `~torch.nn.LPPool2d` for details.
#'
#'
#'
#' @name nnf_lp_pool2d
#'
#' @export
NULL




#' Math
#'
#' This module provides access to the mathematical functions
#' defined by the C standard.
#'
#'
#'
#' @name nnf_math
#'
#' @export
NULL


#' Max_pool1d
#'
#' Applies a 1D max pooling over an input signal composed of several input
#'     planes.
#' 
#'     See `~torch.nn.MaxPool1d` for details.
#'
#'
#'
#' @name nnf_max_pool1d
#'
#' @export
NULL


#' Max_pool1d_with_indices
#'
#' Applies a 1D max pooling over an input signal composed of several input
#'     planes.
#' 
#'     See `~torch.nn.MaxPool1d` for details.
#'
#'
#'
#' @name nnf_max_pool1d_with_indices
#'
#' @export
NULL


#' Max_pool2d
#'
#' Applies a 2D max pooling over an input signal composed of several input
#'     planes.
#' 
#'     See `~torch.nn.MaxPool2d` for details.
#'
#'
#'
#' @name nnf_max_pool2d
#'
#' @export
NULL


#' Max_pool2d_with_indices
#'
#' Applies a 2D max pooling over an input signal composed of several input
#'     planes.
#' 
#'     See `~torch.nn.MaxPool2d` for details.
#'
#'
#'
#' @name nnf_max_pool2d_with_indices
#'
#' @export
NULL


#' Max_pool3d
#'
#' Applies a 3D max pooling over an input signal composed of several input
#'     planes.
#' 
#'     See `~torch.nn.MaxPool3d` for details.
#'
#'
#'
#' @name nnf_max_pool3d
#'
#' @export
NULL


#' Max_pool3d_with_indices
#'
#' Applies a 3D max pooling over an input signal composed of several input
#'     planes.
#' 
#'     See `~torch.nn.MaxPool3d` for details.
#'
#'
#'
#' @name nnf_max_pool3d_with_indices
#'
#' @export
NULL


#' Max_unpool1d
#'
#' Computes a partial inverse of `MaxPool1d`.
#' 
#'     See `~torch.nn.MaxUnpool1d` for details.
#'
#'
#'
#' @name nnf_max_unpool1d
#'
#' @export
NULL


#' Max_unpool2d
#'
#' Computes a partial inverse of `MaxPool2d`.
#' 
#'     See `~torch.nn.MaxUnpool2d` for details.
#'
#'
#'
#' @name nnf_max_unpool2d
#'
#' @export
NULL


#' Max_unpool3d
#'
#' Computes a partial inverse of `MaxPool3d`.
#' 
#'     See `~torch.nn.MaxUnpool3d` for details.
#'
#'
#'
#' @name nnf_max_unpool3d
#'
#' @export
NULL























#' One_hot
#'
#' @section one_hot(tensor, num_classes=-1) -> LongTensor :
#'
#' Takes LongTensor with index values of shape ``(*)`` and returns a tensor
#' of shape ``(*, num_classes)`` that have zeros everywhere except where the
#' index of last dimension matches the corresponding value of the input tensor,
#' in which case it will be 1.
#' 
#' See also `One-hot on Wikipedia`_ .
#' 
#' .. _One-hot on Wikipedia:
#'     https://en.wikipedia.org/wiki/One-hot
#'
#'
#' @param tensor (LongTensor) class values of any shape.
#' @param num_classes (int) Total number of classes. If set to -1, the number        of classes will be inferred as one greater than the largest class        value in the input tensor.
#'
#' @name nnf_one_hot
#'
#' @export
NULL
















#' Sigmoid
#'
#' @section sigmoid(input) -> Tensor :
#'
#' Applies the element-wise function \eqn{\text{Sigmoid}(x) = \frac{1}{1 + \exp(-x)}}
#' 
#'     See `~torch.nn.Sigmoid` for more details.
#'
#'
#'
#'
#' @name nnf_sigmoid
#'
#' @export
NULL








#' Tanh
#'
#' @section tanh(input) -> Tensor :
#'
#' Applies element-wise,
#'     \eqn{\text{Tanh}(x) = \tanh(x) = \frac{\exp(x) - \exp(-x)}{\exp(x) + \exp(-x)}}
#' 
#'     See `~torch.nn.Tanh` for more details.
#'
#'
#'
#'
#' @name nnf_tanh
#'
#' @export
NULL


#' Torch
#'
#' The torch package contains data structures for multi-dimensional
#' tensors and mathematical operations over these are defined.
#' Additionally, it provides many utilities for efficient serializing of
#' Tensors and arbitrary types, and other useful utilities.
#' 
#' It has a CUDA counterpart, that enables you to run your tensor computations
#' on an NVIDIA GPU with compute capability >= 3.0.
#'
#'
#'
#' @name nnf_torch
#'
#' @export
NULL








#' Upsample
#'
#' Upsamples the input to either the given `size` or the given
#'     `scale_factor`
#' 
#'     .. warning::
#'         This function is deprecated in favor of [`torch_nn.functional.interpolate`].
#'         This is equivalent with ``nn.functional.interpolate(...)``.
#' 
#'     .. include:: cuda_deterministic_backward.rst
#' 
#'     The algorithm used for upsampling is determined by `mode`.
#' 
#'     Currently temporal, spatial and volumetric upsampling are supported, i.e.
#'     expected inputs are 3-D, 4-D or 5-D in shape.
#' 
#'     The input dimensions are interpreted in the form:
#'     `mini-batch x channels x [optional depth] x [optional height] x width`.
#' 
#'     The modes available for upsampling are: `nearest`, `linear` (3D-only),
#'     `bilinear`, `bicubic` (4D-only), `trilinear` (5D-only)
#'
#' @param input (Tensor) the input tensor
#' @param size (int or Tuple[int] or Tuple[int, int] or Tuple[int, int, int]) output spatial size.
#' @param scale_factor (float or Tuple[float]) multiplier for spatial size. Has to be an integer.
#' @param mode (string) algorithm used for upsampling:        ``'nearest'`` | ``'linear'`` | ``'bilinear'`` | ``'bicubic'`` |        ``'trilinear'``. Default: ``'nearest'``
#' @param align_corners (bool, optional) Geometrically, we consider the pixels of the        input and output as squares rather than points.        If set to ``True``, the input and output tensors are aligned by the        center points of their corner pixels, preserving the values at the corner pixels.        If set to ``False``, the input and output tensors are aligned by the corner        points of their corner pixels, and the interpolation uses edge value padding        for out-of-boundary values, making this operation *independent* of input size        when `scale_factor` is kept the same. This only has an effect when `mode`        is ``'linear'``, ``'bilinear'``, ``'bicubic'`` or ``'trilinear'``.        Default: ``False``
#'
#' @name nnf_upsample
#'
#' @export
NULL


#' Upsample_bilinear
#'
#' Upsamples the input, using bilinear upsampling.
#' 
#'     .. warning::
#'         This function is deprecated in favor of [`torch_nn.functional.interpolate`].
#'         This is equivalent with
#'         ``nn.functional.interpolate(..., mode='bilinear', align_corners=True)``.
#' 
#'     Expected inputs are spatial (4 dimensional). Use `upsample_trilinear` fo
#'     volumetric (5 dimensional) inputs.
#'
#' @param input (Tensor) input
#' @param size (int or Tuple[int, int]) output spatial size.
#' @param scale_factor (int or Tuple[int, int]) multiplier for spatial size
#'
#' @name nnf_upsample_bilinear
#'
#' @export
NULL


#' Upsample_nearest
#'
#' Upsamples the input, using nearest neighbours' pixel values.
#' 
#'     .. warning::
#'         This function is deprecated in favor of [`torch_nn.functional.interpolate`].
#'         This is equivalent with ``nn.functional.interpolate(..., mode='nearest')``.
#' 
#'     Currently spatial and volumetric upsampling are supported (i.e. expected
#'     inputs are 4 or 5 dimensional).
#'
#' @param input (Tensor) input
#' @param size (int or Tuple[int, int] or Tuple[int, int, int]) output spatia        size.
#' @param scale_factor (int) multiplier for spatial size. Has to be an integer.
#'
#' @name nnf_upsample_nearest
#'
#' @export
NULL


#' Warnings
#'
#' Python part of the warnings subsystem.
#'
#'
#'
#' @name nnf_warnings
#'
#' @export
NULL
