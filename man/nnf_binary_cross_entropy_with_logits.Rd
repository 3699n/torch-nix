% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/gen-nn-functional-docs.R,
%   R/gen-nn-functional-examples.R
\name{nnf_binary_cross_entropy_with_logits}
\alias{nnf_binary_cross_entropy_with_logits}
\title{Binary_cross_entropy_with_logits}
\arguments{
\item{input}{NA Tensor of arbitrary shape}

\item{target}{NA Tensor of the same shape as input}

\item{weight}{(Tensor, optional) a manual rescaling weight        if provided it's repeated to match input tensor shape}

\item{size_average}{(bool, optional) Deprecated (see \code{reduction}). By default,        the losses are averaged over each loss element in the batch. Note that for        some losses, there multiple elements per sample. If the field \code{size_average}        is set to \code{False}, the losses are instead summed for each minibatch. Ignored        when reduce is \code{False}. Default: \code{True}}

\item{reduce}{(bool, optional) Deprecated (see \code{reduction}). By default, the        losses are averaged or summed over observations for each minibatch depending        on \code{size_average}. When \code{reduce} is \code{False}, returns a loss per        batch element instead and ignores \code{size_average}. Default: \code{True}}

\item{reduction}{(string, optional) Specifies the reduction to apply to the output:        \code{'none'} | \code{'mean'} | \code{'sum'}. \code{'none'}: no reduction will be applied,        \code{'mean'}: the sum of the output will be divided by the number of        elements in the output, \code{'sum'}: the output will be summed. Note: \code{size_average}        and \code{reduce} are in the process of being deprecated, and in the meantime,        specifying either of those two args will override \code{reduction}. Default: \code{'mean'}}

\item{pos_weight}{(Tensor, optional) a weight of positive examples.            Must be a vector with length equal to the number of classes.}
}
\description{
Function that measures Binary Cross Entropy between target and output
logits.
}
\details{
\preformatted{See `~torch.nn.BCEWithLogitsLoss` for details.
}
}
\examples{


}
