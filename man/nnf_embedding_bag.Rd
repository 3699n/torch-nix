% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/gen-nn-functional-docs.R,
%   R/gen-nn-functional-examples.R
\name{nnf_embedding_bag}
\alias{nnf_embedding_bag}
\title{Embedding_bag}
\arguments{
\item{input}{(LongTensor) Tensor containing bags of indices into the embedding matrix}

\item{weight}{(Tensor) The embedding matrix with number of rows equal to the maximum possible index + 1,        and number of columns equal to the embedding size}

\item{offsets}{(LongTensor, optional) Only used when \code{input} is 1D. \code{offsets} determines                         the starting index position of each bag (sequence) in \code{input}.}

\item{max_norm}{(float, optional) If given, each embedding vector with norm larger than \code{max_norm}                                is renormalized to have norm \code{max_norm}.                                Note: this will modify \code{weight} in-place.}

\item{norm_type}{(float, optional) The \code{p} in the \code{p}-norm to compute for the \code{max_norm} option.                                 Default \code{2}.}

\item{scale_grad_by_freq}{(boolean, optional) if given, this will scale gradients by the inverse of frequency of                                            the words in the mini-batch. Default \code{False}.                                            Note: this option is not supported when \code{mode="max"}.}

\item{mode}{(string, optional) \code{"sum"}, \code{"mean"} or \code{"max"}. Specifies the way to reduce the bag.                             Default: \code{"mean"}}

\item{sparse}{(bool, optional) if \code{True}, gradient w.r.t. \code{weight} will be a sparse tensor. See Notes under                             \code{torch_nn.Embedding} for more details regarding sparse gradients.                             Note: this option is not supported when \code{mode="max"}.}

\item{per_sample_weights}{(Tensor, optional) a tensor of float / double weights, or None        to indicate all weights should be taken to be 1. If specified, \code{per_sample_weights}        must have exactly the same shape as input and is treated as having the same        \code{offsets}, if those are not None.}

\item{include_last_offset}{(bool, optional) if \code{True}, the size of offsets is equal to the number of bags + 1.}

\item{The}{(sequence)}
}
\description{
Computes sums, means or maxes of \code{bags} of embeddings, without instantiating the
intermediate embeddings.
}
\details{
\preformatted{See `torch_nn.EmbeddingBag` for more details.

.. include:: cuda_deterministic_backward.rst
}
}
\examples{

# an Embedding module containing 10 tensors of size 3
embedding_matrix = torch_rand(10, 3)
# a batch of 2 samples of 4 indices each
input = torch_tensor(c(1,2,4,5,4,3,2,9))
offsets = torch_tensor(c(0,4))
F$embedding_bag(embedding_matrix, input, offsets)
}
