% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/gen-nn-functional-examples.R, R/nnf-loss.R
\name{nnf_nll_loss}
\alias{nnf_nll_loss}
\title{Nll_loss}
\usage{
nnf_nll_loss(input, target, weight = NULL, ignore_index, reduction = "mean")
}
\arguments{
\item{input}{\eqn{(N, C)} where \verb{C = number of classes} or \eqn{(N, C, H, W)} in
case of 2D Loss, or \eqn{(N, C, d_1, d_2, ..., d_K)} where \eqn{K \geq 1} in
the case of K-dimensional loss.}

\item{target}{\eqn{(N)} where each value is \eqn{0 \leq \text{targets}[i] \leq C-1},
or \eqn{(N, d_1, d_2, ..., d_K)} where \eqn{K \geq 1} for K-dimensional loss.}

\item{weight}{(Tensor, optional) a manual rescaling weight given to each class.
If given, has to be a Tensor of size \code{C}}

\item{ignore_index}{(int, optional) Specifies a target value that is ignored and
does not contribute to the input gradient.}

\item{reduction}{(string, optional) â€“ Specifies the reduction to apply to the
output: 'none' | 'mean' | 'sum'. 'none': no reduction will be applied, 'mean':
the sum of the output will be divided by the number of elements in the output,
'sum': the output will be summed. Default: 'mean'}
}
\description{
The negative log likelihood loss.
}
\examples{

# input is of size N x C = 3 x 5
input = torch_randn(3, 5, requires_grad=TRUE)
# each element in target has to have 0 <= value < C
target = torch_tensor(c(1, 0, 4))
output = F$nll_loss(F$log_softmax(input), target)
output$backward()
}
