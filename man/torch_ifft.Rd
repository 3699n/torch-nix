% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/gen-namespace-docs.R
\name{torch_ifft}
\alias{torch_ifft}
\title{Ifft}
\arguments{
\item{input}{(Tensor) the input tensor of at least :attr:\code{signal_ndim} \code{+ 1}        dimensions}

\item{signal_ndim}{(int) the number of dimensions in each signal.        :attr:\code{signal_ndim} can only be 1, 2 or 3}

\item{normalized}{(bool, optional) controls whether to return normalized results.        Default: \code{False}}
}
\description{
ifft(input, signal_ndim, normalized=False) -> Tensor
}
\details{
Complex-to-complex Inverse Discrete Fourier Transform

This method computes the complex-to-complex inverse discrete Fourier
transform. Ignoring the batch dimensions, it computes the following
expression:

\deqn{
    X[\omega_1, \dots, \omega_d] =
        \frac{1}{\prod_{i=1}^d N_i} \sum_{n_1=0}^{N_1-1} \dots \sum_{n_d=0}^{N_d-1} x[n_1, \dots, n_d]
         e^{\ j\ 2 \pi \sum_{i=0}^d \frac{\omega_i n_i}{N_i}},
}
where :math:\code{d} = \code{signal_ndim} is number of dimensions for the
signal, and :math:\code{N_i} is the size of signal dimension :math:\code{i}.

The argument specifications are almost identical with \code{\link{~torch.fft}}.
However, if \code{normalized} is set to \code{True}, this instead returns the
results multiplied by :math:\verb{\\sqrt\{\\prod_\{i=1\}^d N_i\}}, to become a unitary
operator. Therefore, to invert a \link[=`~torch.fft`, the `normalized`]{\code{~torch.fft}, the \code{normalized}}
argument should be set identically for \code{\link{~torch.fft}}.

Returns the real and the imaginary parts together as one tensor of the same
shape of \code{input}.

The inverse of this function is \code{\link{~torch.fft}}.

.. note::
For CUDA tensors, an LRU cache is used for cuFFT plans to speed up
repeatedly running FFT methods on tensors of same geometry with same
configuration. See :ref:\code{cufft-plan-cache} for more details on how to
monitor and control the cache.

.. warning::
For CPU tensors, this method is currently only available with MKL. Use
\code{\link{torch_backends.mkl.is_available}} to check if MKL is installed.
}
\examples{
\dontrun{
x = torch_randn(3, 3, 2)
x
y = torch_fft(x, 2)
torch_ifft(y, 2)  # recover x
}

}
